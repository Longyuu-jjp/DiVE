<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer.">
  <meta name="keywords" content="DiVE, Multi-View, Generation, DiT">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/Longyuu-jjp">Junpeng Jiang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://dblp.org/pid/360/9951.html">Gangyi Hong</a><sup>3,2</sup>,</span>
            <span class="author-block">
              <a href="https://miaozhang0525.github.io/">Miao Zhang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=tF5tWsMAAAAJ&hl=zh-CN">Hengtong Hu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/ZhanKunLiAuto">Kun Zhan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://rshaojimmy.github.io/OrionLab/">Rui Shao</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://liqiangnie.github.io/index.html">Liqiang Nie</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Harbin Institute of Technology (Shenzhen),</span>
            <span class="author-block"><sup>2</sup>Li Auto Inc.,</span>
            <span class="author-block"><sup>3</sup>Tsinghua University</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">DiVE</span> won <b>first place</b> in the <a href="https://coda-dataset.github.io/w-coda2024/track2/">
          Corner Case Scene Generation</a> track of ECCV 2024 W-CODA (Multimodal Perception and Comprehension of 
          Corner Cases in Autonomous Driving challenge).
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser_video.SVG"
           alt="teaser-image">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">DiVE</span> in qualitative visualizations and comparison of results under different acceleration techniques.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Collecting multi-view driving scenario videos to enhance the performance of 3D 
            visual perception presents significant challenges and incurs substantial costs, 
            making generative models for realistic data an appealing alternative. Yet, videos 
            generated by recent works suffer from poor quality and spatiotemporal consistency, 
            hindering their application in driving perception. To address this gap, we propose 
            <span class="dnerf">DiVE</span>, a diffusion transformer-based generative framework 
            engineered to produce high-fidelity, temporally and cross-view consistent multi-view 
            videos, aligning seamlessly with bird's-eye view layouts and textual descriptions. Specifically, 
            DiVE leverages unified cross-attention and a SketchFormer to exert precise control 
            over multi-modal data, while incorporating a view-inflated attention mechanism that 
            adds no extra parameters, thereby guaranteeing consistency across views. Despite 
            these advancements, synthesizing high-resolution videos under multimodal constraints 
            introduces dual challenges: investigating optimal classifier-free guidance (CFG) 
            coniguration under intricate multi-condition inputs and mitigating excessive 
            computational latency in high-resolution rendering---both remain underexplored in 
            prior research. To resolve these limitations, we introduce two technical innovations: 
            (1) Multi-Control Auxiliary Branch Distillation, which streamlines multi-condition 
            CFG selection while circumventing high computational overhead, and (2) Resolution 
            Progressive Sampling, a training-free acceleration strategy that staggers resolution 
            scaling to reduce high latency due to high resolution. These innovations collectively 
            achieve a 2.62$\times$ speedup with minimal quality degradation. Evaluated on the 
            nuScenes dataset, DiVE achieves state-of-the-art performance in multi-view video 
            generation, yielding photorealistic outputs with exceptional temporal and cross-view 
            coherence. By bridging the gap between synthetic data quality and real-world perceptual 
            requirements, <span class="dnerf">DiVE</span> establishes a robust generative paradigm 
            to catalyze significant advancements in 3D perception systems.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <h2 class="title is-3">Proposed Method</h2>
    <div class="content">
      <img src="./static/images/method.svg"
          alt="Overview of DiVE."/>
    </div>

    <!-- Acceleration. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Two Acceleration Tenchniques</h2>

        <div class="columns">
          <!-- MAD. -->
          <div class="column">
            <div class="content">
              <h3 class="title is-4">Multi-Control Auxiliary Branch Distillation</h3>
              <p>
                It mitigates multi-condition CFG complexity via condition-specific auxiliary 
                branches, enhanced by cross-condition knowledge distillation via mixed-control 
                guidance training.
              </p>
              <img src="./static/images/mad.svg"
                  alt="Overview of MAD."/>
            </div>
          </div>
          <br/>
          <!--/ MAD. -->

          <!-- RPS. -->
          <div class="column">
            <div class="content">
              <h3 class="title is-4">Resolution Progressively Sampling</h3>
              <p>
                It's a training-free acceleration strategy, where the inference mode with 
                progressively increasing resolution alleviates the computational burden 
                required for the early-stage inference.
              </p>
              <img src="./static/images/rps.svg"
                  alt="Overview of RPS."/>
            </div>
          </div>
          <!--/ RPS. -->
        </div>

      </div>
    </div>
    <!--/ Acceleration. -->

  </div>
</section>

<section class="section">
  <div class="container">
    <h3 class="title is-4">Quantitative comparison of driving scenario generation methods evaluated on the nuScenes validation set</h3>
    <img src="./static/images/cmp.png" alt="cmp image">
  </div>
</section>

<section class="section">
  <div class="container">
    <h3 class="title is-4">Qualitative comparison of DiVE with MagicDrive, Panacea, MagicDrive-V2 and UniMLVG</h3>
    <div id="results-carousel" class="carousel results-carousel">
      <div class="item" style="text-align:center;">
        <img src="./static/images/vis_cmp_magicdrive_panacea.jpg" alt="Image 1" style="width:100%;"/>
      </div>
      <div class="item" style="text-align:center;">
        <img src="./static/images/vis_cmp_magicdrive_panacea_sup.jpg" alt="Image 2" style="width:50%;"/>
      </div>
      <div class="item" style="text-align:center;">
        <img src="./static/images/vis_cmp_magicdrive_panacea_sup_2.jpg" alt="Image 3" style="width:50%;"/>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <h3 class="title is-4">Visualizations of BEV Layouts, ground truth, and DiVE-generated results on our internal dataset</h3>
    <div id="results-carousel" class="carousel results-carousel">
      <div class="item" style="text-align:center;">
        <img src="./static/images/liauto.jpg" alt="Image 1" style="width:100%;"/>
      </div>
      <div class="item" style="text-align:center;">
        <img src="./static/images/liauto2.jpg" alt="Image 2" style="width:100%;"/>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Long video generation on the nuScenes dataset</h2>
      <div class="content has-text-justified">
        <p>
          Long videos generated by DiVE (up to 240 frames at 12 Hz) on the nuScenes dataset.
        </p>
      </div>

      <h2 class="title is-4">Sunny Day</h2>
      <div class="item item-video1">
        <video poster="" id="video1" controls muted loop height="100%">
          <!-- Your video file here -->
          <source src="./static/videos/sunny/80c91574d0174206a74435200aba8ba8.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item item-video1">
        <video poster="" id="video1" controls muted loop height="100%">
          <!-- Your video file here -->
          <source src="./static/videos/sunny/604d12ebcf784c3f945189f79262f19c.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item item-video1">
        <video poster="" id="video1" controls muted loop height="100%">
          <!-- Your video file here -->
          <source src="./static/videos/sunny/23779301ebc34c1284e539ddf057f0b4.mp4" type="video/mp4">
        </video>
      </div>

      <h2 class="title is-4">Rainy Day</h2>
      <div class="item item-video2">
        <video poster="" id="video2" controls muted loop height="100%">
          <!-- Your video file here -->
          <source src="./static/videos/rainy/80c91574d0174206a74435200aba8ba8.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item item-video2">
        <video poster="" id="video2" controls muted loop height="100%">
          <!-- Your video file here -->
          <source src="./static/videos/rainy/604d12ebcf784c3f945189f79262f19c.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item item-video2">
        <video poster="" id="video2" controls muted loop height="100%">
          <!-- Your video file here -->
          <source src="./static/videos/rainy/23779301ebc34c1284e539ddf057f0b4.mp4" type="video/mp4">
        </video>
      </div>
      
      <h2 class="title is-4">At Night</h2>
      <div class="item item-video3">
        <video poster="" id="video3" controls muted loop height="100%">\
          <!-- Your video file here -->
          <source src="./static/videos/night/80c91574d0174206a74435200aba8ba8.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item item-video3">
        <video poster="" id="video3" controls muted loop height="100%">\
          <!-- Your video file here -->
          <source src="./static/videos/night/604d12ebcf784c3f945189f79262f19c.mp4" type="video/mp4">
        </video>
      </div>
      <div class="item item-video3">
        <video poster="" id="video3" controls muted loop height="100%">\
          <!-- Your video file here -->
          <source src="./static/videos/night/23779301ebc34c1284e539ddf057f0b4.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

</body>
</html>
